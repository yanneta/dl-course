{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Comprehension /Question Answering\n",
    "\n",
    "Code for the Attention reader describe in the paper: https://arxiv.org/pdf/1606.02858v2.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "from torchtext.data import Field\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change your path here\n",
    "PATH = Path(\"/data2/yinterian/reading_comprehension\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Get data\n",
    "\n",
    "Get the data from here https://cs.nyu.edu/~kcho/DMQA/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mtest\u001b[0m/  \u001b[01;34mtraining\u001b[0m/  \u001b[01;34mvalidation\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "ls $PATH/data/cnn/questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_path = PATH/\"data/cnn/questions/training\"\n",
    "valid_path = PATH/\"data/cnn/questions/validation\"\n",
    "train_questions = list(Path(train_path).glob('*.question'))\n",
    "valid_questions = list(Path(valid_path).glob('*.question'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(380298, 3924)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_questions), len(valid_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/data2/yinterian/reading_comprehension/data/cnn/questions/training/8914bf26caeb006f46972fc09b6d54157f11c9a9.question'),\n",
       " PosixPath('/data2/yinterian/reading_comprehension/data/cnn/questions/training/8c95933a89ed1868c0a0c6b8eff519d71b9278f2.question'),\n",
       " PosixPath('/data2/yinterian/reading_comprehension/data/cnn/questions/training/2f97a8b7e4a2566bfafce1657a7ae3430ea873bf.question'),\n",
       " PosixPath('/data2/yinterian/reading_comprehension/data/cnn/questions/training/bc06dc9ba6b2e06961f0d147f80533e044aa8dbb.question'),\n",
       " PosixPath('/data2/yinterian/reading_comprehension/data/cnn/questions/training/700864902e8c607caf14bb436946cc74ecb5cef8.question')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_questions[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Note that this data has already been cleaned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://web.archive.org/web/20150421065616id_/http://www.cnn.com/2015/01/02/politics/clinton-aide-white-house/\r\n",
      "\r\n",
      "@entity0 ( @entity1 ) the @entity4 administration 's top aide in charge of promoting @entity7 enrollment is leaving the @entity8 , possibly with eyes on helping another @entity10 win the job in 2016 . @entity12 , an aide to @entity14 's 2008 presidential campaign , is leaving the @entity8 to rejoin 270 strategies , a @entity17 consulting firm he helped found . \" i am thrilled today to announce i will be returning to the management team of 270 strategies , \" @entity12 , who served as deputy director of the @entity19 , said in a statement . \" i want to thank the president for the opportunity to serve and senior advisor @entity25 for being an amazing boss and mentor . \" word of @entity12 's departure from the @entity8 had been rumored for months , both inside and outside 270 strategies . @entity30 reported in december that he was thought to rejoin the consulting firm and the @entity32 broke the story friday morning . the now former @entity8 aide is close with @entity35 , an operative who many @entity17 see as the frontrunner for @entity38 's 2016 campaign manager job . @entity35 and @entity12 worked together on @entity38 and @entity4 's 2008 campaigns and share a small group of confidants and friends . if @entity43 is tapped for the top campaign job , @entity12 is expected to get a top position , too . the @entity46 oddly played out last year when emails for a group of people - the self - proclaimed \" @entity51 \" -- were leaked to @entity50 . in them , @entity12 -- who refers to himself as \" reverend \" - congratulated friends working on campaigns for \" crushing it mafia style . \" \" @entity58 . @entity51 till i die , \" @entity12 wrote in one email obtained by @entity50 . \" if you have just a few minutes , hop on that activate and punish those voters ! \" @entity12 said he was returning to 270 strategies because of the group 's commitment to \" doing big things and having a meaningful impact on the issues and communities we care about . \" \" it was our deep - seated belief that grassroots organizing is a necessary component to making change in those communities , \" @entity12 said . \" today , the 270 mission is stronger than ever , and i could not be more excited to rejoin the team . \"\r\n",
      "\r\n",
      "he is close with the man widely seen as the frontrunner to lead @placeholder 's possible 2016 campaign\r\n",
      "\r\n",
      "@entity38\r\n",
      "\r\n",
      "@entity17:Democratic\r\n",
      "@entity30:Buzzfeed\r\n",
      "@entity1:CNN\r\n",
      "@entity0:Washington\r\n",
      "@entity7:Obamacare\r\n",
      "@entity12:Marshall\r\n",
      "@entity4:Obama\r\n",
      "@entity38:Clinton\r\n",
      "@entity10:Democrat\r\n",
      "@entity46:Mook-Marshall\r\n",
      "@entity19:White House Office of Public Engagement\r\n",
      "@entity51:Mafia\r\n",
      "@entity50:ABC\r\n",
      "@entity25:Valerie Jarrett\r\n",
      "@entity32:Washington Post\r\n",
      "@entity43:Mook\r\n",
      "@entity35:Mook\r\n",
      "@entity14:Hillary Clinton\r\n",
      "@entity58:F U Republicans\r\n",
      "@entity8:White House"
     ]
    }
   ],
   "source": [
    "! cat $PATH/data/cnn/questions/training/55482c04581f3c7ca514c55f71c45230bdf4c824.question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_question(in_file):    \n",
    "    documents = []\n",
    "    questions = []\n",
    "    answers = []\n",
    "    num_examples = 0\n",
    "    f = open(in_file, 'r')\n",
    "    lines = f.readlines()\n",
    "    document = lines[2].strip()\n",
    "    question = lines[4].strip()\n",
    "    answer = lines[6].strip()\n",
    "    assert(\"@placeholder\" in question)\n",
    "    assert(\"@entity\" in answer)\n",
    "    f.close()\n",
    "    return document, question, answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relabeling(document, question, answer):\n",
    "    \n",
    "    q_words = question.split(' ')\n",
    "    d_words = document.split(' ')\n",
    "    assert answer in d_words\n",
    "    \n",
    "\n",
    "    entity_dict = {}\n",
    "    entity_id = 0\n",
    "    for word in d_words + q_words:\n",
    "        if (word.startswith('@entity')) and (word not in entity_dict):\n",
    "            entity_dict[word] = '@entity' + str(entity_id)\n",
    "            entity_id += 1\n",
    "\n",
    "    q_words = [entity_dict[w] if w in entity_dict else w for w in q_words]\n",
    "    d_words = [entity_dict[w] if w in entity_dict else w for w in d_words]\n",
    "    answer = entity_dict[answer]\n",
    "    question = ' '.join(q_words)\n",
    "    document = ' '.join(d_words)\n",
    "\n",
    "    return document, question, answer  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new imacs sport the latest @entity10 i5 / i7 @placeholder architecture ==> @entity12\n",
      "new imacs sport the latest @entity2 i5 / i7 @placeholder architecture ==> @entity3\n"
     ]
    }
   ],
   "source": [
    "document, question, answer = process_question(train_questions[2])\n",
    "print(question, \"==>\", answer)\n",
    "document, question, answer = relabeling(document, question, answer)\n",
    "print(question, \"==>\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(paths):\n",
    "    documents = []\n",
    "    questions = []\n",
    "    answers = []\n",
    "    for path in tqdm(paths):\n",
    "        document, question, answer = process_question(path)\n",
    "        document, question, answer = relabeling(document, question, answer)\n",
    "        documents.append(document)\n",
    "        questions.append(question)\n",
    "        answers.append(answer)\n",
    "    return documents, questions, answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "#documents, questions, answers = load_data(train_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dict(sentences, max_words=50000):\n",
    "    \"\"\"\n",
    "        Build a dictionary for the words in `sentences`.\n",
    "        Only the max_words ones are kept and the remaining will be mapped to <UNK>.\n",
    "    \"\"\"\n",
    "    word_count = Counter()\n",
    "    for sent in sentences:\n",
    "        for w in sent.split(' '):\n",
    "            word_count[w] += 1\n",
    "\n",
    "    words = word_count.most_common(max_words)\n",
    "    # leave 0 to UNK\n",
    "    # leave 1 to delimiter |||\n",
    "    return {w[0]: index + 2 for (index, w) in enumerate(words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict = build_dict(documents + questions)\n",
    "pickle.dump(word_dict, open(PATH/\"word_dict.pickle\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_markers = list(set([w for w in word_dict.keys() if w.startswith('@entity')] + answers))\n",
    "entity_markers = ['<unk_entity>'] + entity_markers\n",
    "entity_dict = {w: index for (index, w) in enumerate(entity_markers)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entity_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "328"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_labels = len(entity_dict)\n",
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(documents, questions, answers, word_dict, entity_dict):\n",
    "    \"\"\"\n",
    "        Vectorize `examples`.\n",
    "        in_x1, in_x2: sequences for document and question respecitvely.\n",
    "        in_y: label\n",
    "        in_l: whether the entity label occurs in the document.\n",
    "    \"\"\"\n",
    "    in_x1 = []\n",
    "    in_x2 = []\n",
    "    in_l = np.zeros((len(documents), len(entity_dict)))\n",
    "    in_y = []\n",
    "    for idx, (d, q, a) in enumerate(zip(documents, questions, answers)):\n",
    "        d_words = d.split(' ')\n",
    "        q_words = q.split(' ')\n",
    "        assert (a in d_words)\n",
    "        seq1 = [word_dict[w] if w in word_dict else 0 for w in d_words]\n",
    "        seq2 = [word_dict[w] if w in word_dict else 0 for w in q_words]\n",
    "        if (len(seq1) > 0) and (len(seq2) > 0):\n",
    "            in_x1.append(seq1)\n",
    "            in_x2.append(seq2)\n",
    "            in_l[idx, [entity_dict[w] for w in d_words if w in entity_dict]] = 1.0\n",
    "            in_y.append(entity_dict[a] if a in entity_dict else 0)\n",
    "\n",
    "    return in_x1, in_x2, in_l, in_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x1, train_x2, train_l, train_y = vectorize(documents, questions, answers, word_dict, entity_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[327, 2021, 5, 5863, 96, 62, 2, 4119, 7529, 11, 4801]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "187"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c78f016048194f07ab8c0d12bef20fa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3924.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "documents, questions, answers = load_data(valid_questions)\n",
    "valid_x1, valid_x2, valid_l, valid_y = vectorize(documents, questions, answers, word_dict, entity_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[96, 480, 504, 306, 10, 7200]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_x2[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = {\"x1\": train_x1, \"x2\": train_x2, \"l\": train_l, \"y\": train_y}\n",
    "valid_dict = {\"x1\": valid_x1, \"x2\": valid_x2, \"l\": valid_l, \"y\": valid_y}\n",
    "pickle.dump(train_dict, open(PATH/\"train_dict.pickle\", 'wb'))\n",
    "pickle.dump(valid_dict, open(PATH/\"valid_dict.pickle\", 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = pickle.load(open(PATH/\"train_dict.pickle\", \"rb\"))\n",
    "valid_dict  = pickle.load(open(PATH/\"valid_dict.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_dict = pickle.load(open(PATH/\"word_dict.pickle\", 'rb'))\n",
    "len(word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(380298, 3924)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dict[\"y\"]), len(valid_dict[\"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QADataset(Dataset):\n",
    "    def __init__(self, d_dict):\n",
    "        self.d_dict = d_dict \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.d_dict[\"y\"])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.d_dict[\"x1\"][idx], self.d_dict[\"x2\"][idx], self.d_dict[\"l\"][idx], self.d_dict[\"y\"][idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = QADataset(train_dict)\n",
    "valid_ds = QADataset(valid_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall:\n",
    "* `x1` tokens from document\n",
    "* `x2` tokens from question\n",
    "* `l` entities present in the document\n",
    "* `y` answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, x2, l, y = train_ds[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([59, 14, 1063, 685, 42, 96, 327, 5, 1439, 2039, 13, 2, 346], 153)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1069"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(328, 19.0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(l), l.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    x1 = [torch.LongTensor(sample[0]) for sample in batch] \n",
    "    x2 = [torch.LongTensor(sample[1]) for sample in batch] \n",
    "    L = torch.LongTensor([sample[2] for sample in batch])\n",
    "    y = torch.LongTensor([sample[3] for sample in batch])\n",
    "    x1lens = np.array([len(seq) for seq in x1])\n",
    "    x2lens = np.array([len(seq) for seq in x2])\n",
    "    \n",
    "    # pad the batch\n",
    "    padded_x1 = torch.zeros(len(x1), x1lens.max()).long()\n",
    "    for idx, length in enumerate(x1lens):\n",
    "        padded_x1[idx, x1lens.max() - length:] = x1[idx]\n",
    "    \n",
    "    padded_x2 = torch.zeros(len(x2), x2lens.max()).long()\n",
    "    for idx, length in enumerate(x2lens):\n",
    "        padded_x2[idx, x2lens.max() - length:] = x2[idx]\n",
    "    \n",
    "    return (padded_x1, padded_x2, L, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = [train_ds[0], train_ds[1], train_ds[10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, x2, l, y = collate_fn(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 1184]),\n",
       " torch.Size([3, 13]),\n",
       " torch.Size([3, 328]),\n",
       " tensor([ 94, 187, 187]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.shape, x2.shape, l.shape, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Debugging Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size=3, shuffle=False, collate_fn=collate_fn)\n",
    "x1, x2, l, y = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "vocab_size = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "emb = nn.Embedding(vocab_size, 10, padding_idx=0)\n",
    "gru1 = nn.GRU(10, 7, batch_first=True)\n",
    "gru2 = nn.GRU(10, 5, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1184, 10]) torch.Size([3, 12, 10])\n"
     ]
    }
   ],
   "source": [
    "x1 = emb(x1)\n",
    "x2 = emb(x2)\n",
    "print(x1.shape, x2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 1184, 7]), torch.Size([3, 5]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hts1, ht1 = gru1(x1)\n",
    "hts2, ht2 = gru2(x2)\n",
    "hts1.shape, ht2[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Note this is just a matrix multiplication\n",
    "liner_att = nn.Linear(7, 5, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1184, 5])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Wp = liner_att(hts1)\n",
    "Wp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5, 1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = ht2[0].unsqueeze(2)\n",
    "q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 1184, 1]), torch.Size([3, 1184]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qWp = torch.bmm(Wp, q)\n",
    "qWp.shape, qWp[:,:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "alpha = F.softmax(qWp, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000]], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1184, 1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1184, 7])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hts1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 7])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = (alpha*hts1).sum(1)\n",
    "o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "linear_out = nn.Linear(7, 328, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 328])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = linear_out(o)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 328])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# masking entities that do not appear in the document\n",
    "out2 = out*l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.7445, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cross_entropy(out2, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 50000 + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentiveReader(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size=vocab_size, emb_dim=100, hidden_dim=50, output_dim=328):\n",
    "        super(AttentiveReader, self).__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n",
    "        self.gruD = nn.GRU(emb_dim, hidden_dim, batch_first=True)\n",
    "        self.gruQ = nn.GRU(emb_dim, hidden_dim, batch_first=True)\n",
    "        self.linear_att = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.linear_out = nn.Linear(hidden_dim, output_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x1, x2, l):\n",
    "        x1 = self.emb(x1)\n",
    "        x1 = self.dropout(x1)\n",
    "        x2 = self.emb(x2)\n",
    "        x2 = self.dropout(x2)\n",
    "        hts, _ = self.gruD(x1)\n",
    "        _, q = self.gruQ(x2)\n",
    "        Wp = self.linear_att(hts)\n",
    "        q = self.bn1(q[0])\n",
    "        qWp = torch.bmm(Wp, q.unsqueeze(2))\n",
    "        alpha = F.softmax(qWp, dim=1)\n",
    "        o = (alpha*hts).sum(1)\n",
    "        o = self.bn2(o) ## try also F.relu\n",
    "        out = self.linear_out(o)\n",
    "        return l*out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AttentiveReader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size=1000, shuffle=False, collate_fn=collate_fn)\n",
    "x1, x2, l, y = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.7947, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model(x1, x2, l)\n",
    "F.cross_entropy(out, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(m, p): torch.save(m.state_dict(), p)\n",
    "    \n",
    "def load_model(m, p): m.load_state_dict(torch.load(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_optimizer(optimizer, lr):\n",
    "    for i, param_group in enumerate(optimizer.param_groups):\n",
    "        param_group[\"lr\"] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_segment(start_lr, end_lr, iterations):\n",
    "    i = np.arange(iterations)\n",
    "    c_i = 1 + np.cos(i*np.pi/iterations)\n",
    "    return end_lr + (start_lr - end_lr)/2 *c_i\n",
    "\n",
    "def get_cosine_triangular_lr(max_lr, iterations):\n",
    "    min_start, min_end = max_lr/5, max_lr/10\n",
    "    iter1 = int(0.2*iterations)\n",
    "    iter2 = iterations - iter1\n",
    "    segs = [cosine_segment(min_start, max_lr, iter1), cosine_segment(max_lr, min_end, iter2)]\n",
    "    return np.concatenate(segs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = 10000\n",
    "lr = get_cosine_triangular_lr(0.005, N)\n",
    "plt.plot(list(range(N)), lr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epocs(model, train_dl, valid_dl, optimizer, epochs=10, num_hidden=50, max_lr=0.005):\n",
    "    iterations = epochs*len(train_dl)\n",
    "    pbar = tqdm(total=iterations)\n",
    "    lrs = get_cosine_triangular_lr(max_lr, iterations)\n",
    "    best_acc = 0\n",
    "    ind = 0\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        sum_loss = 0.0\n",
    "        total = 0\n",
    "        for x1, x2, l, y in train_dl:\n",
    "            update_optimizer(optimizer, lrs[ind])\n",
    "            x1 = x1.cuda()\n",
    "            x2 = x2.cuda()\n",
    "            l = l.cuda()\n",
    "            y = y.cuda()\n",
    "            y_pred = model(x1, x2, l)\n",
    "            optimizer.zero_grad()\n",
    "            loss = F.cross_entropy(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            sum_loss += loss.item()*y.shape[0]\n",
    "            total += y.shape[0]\n",
    "            pbar.update()\n",
    "            ind +=1\n",
    "        val_loss, val_acc = val_metrics(model, valid_dl)\n",
    "        print(\"epoch % d train loss %.3f val loss %.3f and val accuracy %.3f\" % (\n",
    "            i, sum_loss/total, val_loss, val_acc))\n",
    "        if val_acc > best_acc:\n",
    "            path = \"{0}/models/model_att_acc_{1}_{2:.0f}.pth\".format(PATH, num_hidden, 100*val_acc) \n",
    "            save_model(model, path)\n",
    "            best_acc = val_acc\n",
    "            print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_metrics(model, valid_dl):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    sum_loss = 0.0\n",
    "    for x1, x2, l, y in valid_dl:\n",
    "        x1 = x1.cuda()\n",
    "        x2 = x2.cuda()\n",
    "        l = l.cuda()\n",
    "        y = y.cuda()\n",
    "        y_hat = model(x1, x2, l)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        preds = torch.max(y_hat, dim=1)[1]\n",
    "        correct += (preds==y).float().sum().item()\n",
    "        total += y.shape[0]\n",
    "        sum_loss += loss.item()*y.shape[0]\n",
    "    return sum_loss/total, correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_optimizer(optimizer, lr):\n",
    "    for i, param_group in enumerate(optimizer.param_groups):\n",
    "        param_group[\"lr\"] = lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training \n",
    "hidden_dim=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=1000\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bf6ec75843e4e3c81c2d639498a4390",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11430.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0 train loss 3.524 val loss 2.156 and val accuracy 0.387\n",
      "/data2/yinterian/reading_comprehension/models/model_att_acc_128_39.pth\n",
      "epoch  1 train loss 2.044 val loss 1.755 and val accuracy 0.520\n",
      "/data2/yinterian/reading_comprehension/models/model_att_acc_128_52.pth\n",
      "epoch  2 train loss 1.716 val loss 1.543 and val accuracy 0.584\n",
      "/data2/yinterian/reading_comprehension/models/model_att_acc_128_58.pth\n",
      "epoch  3 train loss 1.524 val loss 1.393 and val accuracy 0.630\n",
      "/data2/yinterian/reading_comprehension/models/model_att_acc_128_63.pth\n",
      "epoch  4 train loss 1.387 val loss 1.296 and val accuracy 0.657\n",
      "/data2/yinterian/reading_comprehension/models/model_att_acc_128_66.pth\n",
      "epoch  5 train loss 1.293 val loss 1.266 and val accuracy 0.662\n",
      "/data2/yinterian/reading_comprehension/models/model_att_acc_128_66.pth\n",
      "epoch  6 train loss 1.219 val loss 1.262 and val accuracy 0.663\n",
      "/data2/yinterian/reading_comprehension/models/model_att_acc_128_66.pth\n",
      "epoch  7 train loss 1.161 val loss 1.249 and val accuracy 0.672\n",
      "/data2/yinterian/reading_comprehension/models/model_att_acc_128_67.pth\n",
      "epoch  8 train loss 1.114 val loss 1.263 and val accuracy 0.674\n",
      "/data2/yinterian/reading_comprehension/models/model_att_acc_128_67.pth\n",
      "epoch  9 train loss 1.070 val loss 1.258 and val accuracy 0.670\n"
     ]
    }
   ],
   "source": [
    "model = AttentiveReader(hidden_dim=128).cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "train_epocs(model, train_dl, valid_dl, optimizer, epochs=30, num_hidden=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AttentiveReader(hidden_dim=128).cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "train_epocs(model, train_dl, valid_dl, optimizer, epochs=30, num_hidden=128, max_lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AttentiveReader(hidden_dim=128).cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "train_epocs(model, train_dl, valid_dl, optimizer, epochs=30, num_hidden=128, max_lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=1400\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AttentiveReaderBN(hidden_dim=50).cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "train_epocs(model, train_dl, valid_dl, optimizer, epochs=20, num_hidden=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AttentiveReader(hidden_dim=50).cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "train_epocs(model, train_dl, valid_dl, optimizer, epochs=30, num_hidden=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AttentiveReaderBN(hidden_dim=50).cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "train_epocs(model, train_dl, valid_dl, optimizer, epochs=30, num_hidden=50, lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model v2\n",
    "* We need bidirectional LSTMs\n",
    "* Initialize with pre-trained embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "* https://arxiv.org/pdf/1606.02858v2.pdf\n",
    "* https://github.com/danqi/rc-cnn-dailymail\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
